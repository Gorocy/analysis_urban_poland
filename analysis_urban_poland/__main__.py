"""Main entrypoint for running the top-level package (if runnable)."""

import os
import pandas as pd
import matplotlib.pyplot as plt
import geopandas as gpd
import numpy as np
from typing import Any, Dict, List, Optional
from .map_loader import MapLoader
from .data_loader import DataLoader
from .legend_calculator import LegendCalculator
from .map_visualizer import MapVisualizer

def analyze_migration_years():
    # Inicjalizacja komponent√≥w
    map_loader = MapLoader(base_map_path='data/map')
    data_loader = DataLoader(
        migracje_path='data/migracje_wew_i_zew/all.csv',
        bezrobocie_path='data/bezrobocie/RYNE_1944_CTAB_20250616184618.csv',
        ludnosc_path='data/ludnosc/ludnosc.csv'
    )
    legend_calculator = LegendCalculator()
    map_visualizer = MapVisualizer(legend_calculator)

    # Lista do przechowywania wynik√≥w korelacji
    correlation_results = []

    # Iteracja po latach
    for year in range(2005, 2024):
        # Wczytanie mapy dla danego roku
        mapa = map_loader.get_map_for_year(year)
        if mapa is None:
            print(f"Nie uda≈Ço siƒô wczytaƒá mapy dla roku {year}!")
            continue

        print(f"\nRok {year}:")
        print("Przyk≈Çadowe kody z mapy:", mapa['Kod'].head())
        print("Liczba unikalnych kod√≥w w mapie:", mapa['Kod'].nunique())

        # Pobranie danych dla roku
        migr_data, bezr_data, pop_data = data_loader.get_data_for_year(year)
        if pop_data is None:
            print(f"Brak danych ludno≈õci dla roku {year}")
            continue
        
        print("Przyk≈Çadowe kody z ludno≈õci:", pop_data['Kod'].head())
        print("Liczba unikalnych kod√≥w w ludno≈õci:", pop_data['Kod'].nunique())
        
        # Dla lat 2005-2014: korelacja migracja vs ludno≈õƒá
        # Dla lat 2015-2023: korelacja migracja vs bezrobocie (jak wcze≈õniej)
        # if year < 2015:
        if year < 2003:
            # Korelacja z liczbƒÖ ludno≈õci
            if migr_data is not None:
                print("Przyk≈Çadowe kody z migracji:", migr_data['Kod'].head())
                print("Liczba unikalnych kod√≥w w migracji:", migr_data['Kod'].nunique())
                
                # Znajd≈∫ kolumny migracji
                migration_cols = data_loader.get_migration_columns_for_year(year)
                print("Dostƒôpne kolumny migracji:", list(migration_cols.keys()))
                
                # Po≈ÇƒÖcz dane migracji z mapƒÖ i ludno≈õciƒÖ
                mapa_migr = mapa.merge(migr_data, on='Kod', how='left').merge(pop_data[['Kod', 'Ludnosc']], on='Kod', how='left')
                
                # U≈ºyj kolumny 'saldo' i oblicz saldo na 1000 ludno≈õci
                if 'saldo' in migration_cols:
                    migr_col = migration_cols['saldo']
                    
                    # Sprawd≈∫ czy kolumna zosta≈Ça dodana do dataframe i ma dane
                    if migr_col in mapa_migr.columns:
                        # Sprawd≈∫ dane migracji przed po≈ÇƒÖczeniem z mapƒÖ
                        original_valid_count = migr_data[migr_col].dropna().count()
                        print(f"Oryginalne dane migracji: {original_valid_count} prawid≈Çowych warto≈õci")
                        
                        # Sprawd≈∫ dane po po≈ÇƒÖczeniu z mapƒÖ
                        merged_valid_count = mapa_migr[migr_col].dropna().count()
                        print(f"Dane po po≈ÇƒÖczeniu z mapƒÖ: {merged_valid_count} prawid≈Çowych warto≈õci")
                        
                        if merged_valid_count > 0:
                            print(f"U≈ºywam kolumny saldo dla roku {year} ({merged_valid_count} prawid≈Çowych warto≈õci)")
                            
                            # Oblicz saldo migracji na 1000 ludno≈õci
                            # Najpierw sprawd≈∫ czy mamy dane ludno≈õci
                            pop_valid_count = mapa_migr['Ludnosc'].dropna().count()
                            print(f"Dane ludno≈õci po po≈ÇƒÖczeniu: {pop_valid_count} prawid≈Çowych warto≈õci")
                            
                            if pop_valid_count > 0:
                                # Oblicz tylko dla rekord√≥w gdzie mamy zar√≥wno migracjƒô jak i ludno≈õƒá
                                mask = mapa_migr[migr_col].notna() & mapa_migr['Ludnosc'].notna() & (mapa_migr['Ludnosc'] > 0)
                                mapa_migr.loc[mask, 'saldo_na_1000'] = (mapa_migr.loc[mask, migr_col] / mapa_migr.loc[mask, 'Ludnosc']) * 1000
                                
                                # Sprawd≈∫ czy obliczenie siƒô powiod≈Ço
                                valid_saldo_1000 = mapa_migr['saldo_na_1000'].dropna().count()
                                if valid_saldo_1000 > 0:
                                    print(f"Obliczono saldo na 1000 ludno≈õci ({valid_saldo_1000} prawid≈Çowych warto≈õci)")
                                    print("Przyk≈Çadowe warto≈õci saldo na 1000:", mapa_migr['saldo_na_1000'].dropna().head())
                                    
                                    # Sprawd≈∫ czy wszystkie warto≈õci sƒÖ identyczne (problem z universalnƒÖ skalƒÖ)
                                    unique_values = mapa_migr['saldo_na_1000'].dropna().nunique()
                                    if unique_values <= 1:
                                        print(f"Wszystkie warto≈õci saldo na 1000 sƒÖ identyczne ({unique_values} unikalnych warto≈õci) - pomijam uniwersalnƒÖ skalƒô")
                                        skip_universal = True
                                    else:
                                        skip_universal = False
                                    
                                    # Oblicz zakresy dla saldo na 1000
                                    legend_calculator.calculate_ranges(mapa_migr, year, 'saldo_na_1000', 'migracja_saldo_1000')
                                    
                                    # Stw√≥rz folder na mapy
                                    os.makedirs('mapy', exist_ok=True)
                                    
                                    # Tw√≥rz mapƒô z indywidualnƒÖ skalƒÖ
                                    map_visualizer.create_map(
                                        mapa_migr,
                                        year,
                                        'saldo_na_1000',
                                        f'Migration balance per 1000 people {year}',
                                        f'mapy/migracja_saldo_1000_{year}.png',
                                        data_type='migracja_saldo_1000'
                                    )
                                    
                                    # Tw√≥rz mapƒô z uniwersalnƒÖ skalƒÖ tylko je≈õli warto≈õci siƒô r√≥≈ºniƒÖ
                                    if not skip_universal:
                                        map_visualizer.create_map(
                                            mapa_migr,
                                            year,
                                            'saldo_na_1000',
                                            f'Migration balance per 1000 people {year} (universal scale)',
                                            f'mapy/migracja_saldo_1000_{year}_uniwersalna.png',
                                            use_universal_scale=True,
                                            data_type='migracja_saldo_1000'
                                        )
                                    else:
                                        print(f"Pomijam mapƒô z uniwersalnƒÖ skalƒÖ dla roku {year} - wszystkie warto≈õci identyczne")
                                    
                                    # Oblicz korelacjƒô miƒôdzy migracjƒÖ a liczbƒÖ ludno≈õci
                                    correlation_data = calculate_correlation_with_population(mapa_migr, 'saldo_na_1000', year, 'saldo_1000')
                                    if correlation_data:
                                        correlation_results.append(correlation_data)
                                else:
                                    print(f"Nie uda≈Ço siƒô obliczyƒá saldo na 1000 ludno≈õci dla roku {year}")
                            else:
                                print(f"Brak danych ludno≈õci po po≈ÇƒÖczeniu dla roku {year}")
                        else:
                            print(f"Nie znaleziono kolumny saldo w dataframe dla roku {year}")
                    else:
                        print(f"Brak kolumny saldo dla roku {year}")
                else:
                    print(f"Brak danych migracji dla roku {year}")
            else:
                print(f"Brak danych migracji dla roku {year}")
        else:
            # Lata 2015-2023: korelacja z bezrobociem (jak wcze≈õniej)
            if bezr_data is None:
                print(f"Brak danych bezrobocia dla roku {year}")
                continue
            
            print("Przyk≈Çadowe kody z bezrobocia:", bezr_data['Kod'].head())
            print("Liczba unikalnych kod√≥w w bezrobociu:", bezr_data['Kod'].nunique())
            
            # Po≈ÇƒÖczenie danych z mapƒÖ
            mapa_bezr = mapa.merge(bezr_data, on='Kod', how='left').merge(pop_data[['Kod', 'Ludnosc']], on='Kod', how='left')
            bezr_col = [c for c in bezr_data.columns if f'{year}' in c and 'osoba' in c][0]
            # Oblicz bezrobocie na 1000 mieszka≈Ñc√≥w
            mapa_bezr['bezrobocie_na_1000'] = (mapa_bezr[bezr_col] / mapa_bezr['Ludnosc']) * 1000
            print("Przyk≈Çadowe warto≈õci bezrobocia na 1000:", mapa_bezr['bezrobocie_na_1000'].head())

            # Obliczenie zakres√≥w dla legendy
            legend_calculator.calculate_ranges(mapa_bezr, year, 'bezrobocie_na_1000', 'bezrobocie')

            # Tworzenie map bezrobocia
            os.makedirs('mapy', exist_ok=True)
            map_visualizer.create_map(
                mapa_bezr,
                year,
                'bezrobocie_na_1000',
                f'Bezrobocie na 1000 os√≥b {year}',
                f'mapy/bezrobocie_{year}_na_1000.png',
                data_type='bezrobocie'
            )
            map_visualizer.create_map(
                mapa_bezr,
                year,
                'bezrobocie_na_1000',
                f'Bezrobocie na 1000 os√≥b {year} (skala uniwersalna)',
                f'mapy/bezrobocie_{year}_na_1000_uniwersalna.png',
                use_universal_scale=True,
                data_type='bezrobocie'
            )

            # Tworzenie map migracji i obliczanie korelacji
            if migr_data is not None:
                print("Przyk≈Çadowe kody z migracji:", migr_data['Kod'].head())
                print("Liczba unikalnych kod√≥w w migracji:", migr_data['Kod'].nunique())
                
                # Znajd≈∫ kolumny migracji
                migration_cols = data_loader.get_migration_columns_for_year(year)
                print("Dostƒôpne kolumny migracji:", list(migration_cols.keys()))
                
                # Po≈ÇƒÖcz dane migracji z mapƒÖ
                mapa_migr = mapa.merge(migr_data, on='Kod', how='left')
                
                # Tw√≥rz mapy tylko dla saldo_1000 (znormalizowane)
                if 'saldo_1000' in migration_cols:
                    migr_col = migration_cols['saldo_1000']
                    migr_type = 'saldo_1000'
                    
                    if migr_col in mapa_migr.columns:
                        print(f"Tworzenie mapy {migr_type} dla roku {year}")
                        
                        # Oblicz zakresy dla tego typu migracji
                        legend_calculator.calculate_ranges(mapa_migr, year, migr_col, f'migracja_{migr_type}')
                        
                        # Tw√≥rz mapƒô z indywidualnƒÖ skalƒÖ
                        map_visualizer.create_map(
                            mapa_migr,
                            year,
                            migr_col,
                            f'{migr_type.title()} {year}',
                            f'mapy/migracja_{migr_type}_{year}.png',
                            data_type=f'migracja_{migr_type}'
                        )
                        
                        # Tw√≥rz mapƒô z uniwersalnƒÖ skalƒÖ
                        map_visualizer.create_map(
                            mapa_migr,
                            year,
                            migr_col,
                            f'{migr_type.title()} {year} (skala uniwersalna)',
                            f'mapy/migracja_{migr_type}_{year}_uniwersalna.png',
                            use_universal_scale=True,
                            data_type=f'migracja_{migr_type}'
                        )
                        
                        # Przeprowad≈∫ zaawansowanƒÖ analizƒô przyczynowo-skutkowƒÖ
                        analysis_data = perform_advanced_migration_unemployment_analysis(
                            mapa_migr, mapa_bezr, migr_col, bezr_col, year, migr_type
                        )
                        if analysis_data:
                            correlation_results.append(analysis_data)
                    else:
                        print(f"Brak kolumny saldo_1000 dla roku {year}")
                else:
                    print(f"Brak kolumny saldo_1000 dla roku {year}")
            else:
                print(f"Brak danych migracji dla roku {year}")

    # Zapisz wyniki analizy do pliku CSV
    if correlation_results:
        df_results = pd.DataFrame(correlation_results)
        df_results.to_csv('wyniki_analizy_przyczynowej.csv', index=False, encoding='utf-8')
        print(f"\n‚úÖ Zapisano wyniki analizy przyczynowej do: wyniki_analizy_przyczynowej.csv")
        
        # Przeprowad≈∫ analizƒô czasowƒÖ
        perform_temporal_causality_analysis(correlation_results)
        
        # Stw√≥rz podsumowanie analizy
        create_analysis_summary(correlation_results)
    else:
        print("\n‚ùå Brak wynik√≥w do zapisania")

    # Tw√≥rz zaawansowane wizualizacje migracji
    print("\n=== Tworzenie zaawansowanych wizualizacji migracji ===")
    # U≈ºyj mapy z najnowszego roku (2023) dla zaawansowanych wizualizacji
    mapa_advanced = map_loader.get_map_for_year(2023)
    if mapa_advanced is not None:
        create_advanced_migration_visualizations(map_visualizer, mapa_advanced, data_loader)
        # Tw√≥rz animacje bezrobocia z poprawnymi legendami
        create_unemployment_animations(map_visualizer, mapa_advanced, data_loader)
    else:
        print("Nie uda≈Ço siƒô wczytaƒá mapy dla zaawansowanych wizualizacji")

    print("\n=== Zako≈Ñczono tworzenie zaawansowanych wizualizacji ===")
    print("\nüìä PODSUMOWANIE ULEPSZE≈É:")
    print("‚úÖ Strza≈Çki w flow maps zosta≈Çy powiƒôkszone 3x")
    print("‚úÖ Legenda w animacji choropleth zosta≈Ça uproszczona")
    print("‚úÖ Dodano szczeg√≥≈Çowe flow maps z wiƒôkszƒÖ liczbƒÖ strza≈Çek")
    print("‚úÖ Zwiƒôkszono czytelno≈õƒá wszystkich element√≥w")
    print(f"\nüìÅ Sprawd≈∫ wyniki w folderach:")
    print("   ‚Ä¢ mapy/flow_maps/ - mapy przep≈Çyw√≥w")
    print("   ‚Ä¢ mapy/hotspots/ - mapy hot spot√≥w") 
    print("   ‚Ä¢ mapy/animations/ - animacje czasowe")
    print("   ‚Ä¢ mapy/comparisons/ - mapy por√≥wnawcze")

def calculate_correlation_with_population(mapa_migr: Any, migr_col: str, year: int, migr_type: str) -> Optional[Dict[str, Any]]:
    """Oblicza korelacjƒô miƒôdzy migracjƒÖ a liczbƒÖ ludno≈õci."""
    try:
        # Usu≈Ñ brakujƒÖce warto≈õci
        correlation_data = mapa_migr[['Kod', migr_col, 'Ludnosc']].dropna()
        
        if len(correlation_data) < 10:  # Minimum 10 obserwacji
            print(f"  Zbyt ma≈Ço danych dla korelacji {migr_type} vs ludno≈õƒá ({len(correlation_data)} obserwacji)")
            return None
        
        # Oblicz korelacjƒô
        correlation = correlation_data[migr_col].corr(correlation_data['Ludnosc'])
        
        print(f"  Korelacja {migr_type} vs ludno≈õƒá: {correlation:.3f} (n={len(correlation_data)})")
        
        # Stw√≥rz wykres korelacji
        create_correlation_scatter_population(correlation_data, migr_col, year, migr_type, correlation)
        
        return {
            'year': year,
            'migration_type': migr_type,
            'correlation': correlation,
            'n_observations': len(correlation_data),
            'migration_mean': correlation_data[migr_col].mean(),
            'migration_std': correlation_data[migr_col].std(),
            'population_mean': correlation_data['Ludnosc'].mean(),
            'population_std': correlation_data['Ludnosc'].std(),
            'comparison_variable': 'ludno≈õƒá'
        }
        
    except Exception as e:
        print(f"  B≈ÇƒÖd przy obliczaniu korelacji {migr_type} vs ludno≈õƒá: {e}")
        return None

def create_correlation_scatter_population(data: Any, migr_col: str, year: int, migr_type: str, correlation: float) -> None:
    """Tworzy wykres punktowy korelacji z ludno≈õciƒÖ."""
    plt.figure(figsize=(8, 6))
    plt.scatter(data[migr_col], data['Ludnosc'], alpha=0.6, s=30)
    plt.xlabel(f'{migr_type.title()} (people)', fontsize=12)
    plt.ylabel('Population count', fontsize=12)
    plt.title(f'Correlation {migr_type} vs population {year}', fontsize=14, fontweight='bold')
    plt.grid(True, alpha=0.3)
    
    # Dodaj informacjƒô o korelacji
    plt.text(0.05, 0.95, f'r = {correlation:.3f}\nn = {len(data)}', 
             transform=plt.gca().transAxes, fontsize=12, 
             bbox=dict(boxstyle="round,pad=0.3", facecolor="white", alpha=0.8),
             verticalalignment='top')
    
    plt.tight_layout()
    os.makedirs('korelacje', exist_ok=True)
    plt.savefig(f'korelacje/korelacja_{migr_type}_ludnosc_{year}.png', dpi=150, bbox_inches='tight')
    plt.close()
    print(f"  Zapisano wykres korelacji: korelacje/korelacja_{migr_type}_ludnosc_{year}.png")

def calculate_correlation(mapa_migr: Any, mapa_bezr: Any, migr_col: str, bezr_col: str, year: int, migr_type: str) -> Optional[Dict[str, Any]]:
    """Oblicza korelacjƒô miƒôdzy migracjƒÖ a bezrobociem."""
    try:
        # Po≈ÇƒÖcz dane migracji i bezrobocia
        correlation_data = mapa_migr[['Kod', migr_col]].merge(
            mapa_bezr[['Kod', bezr_col]], on='Kod', how='inner'
        )
        
        # Usu≈Ñ brakujƒÖce warto≈õci
        correlation_data = correlation_data.dropna()
        
        if len(correlation_data) < 10:  # Minimum 10 obserwacji
            print(f"  Zbyt ma≈Ço danych dla korelacji {migr_type} vs bezrobocie ({len(correlation_data)} obserwacji)")
            return None
        
        # Oblicz korelacjƒô
        correlation = correlation_data[migr_col].corr(correlation_data[bezr_col])
        
        print(f"  Korelacja {migr_type} vs bezrobocie: {correlation:.3f} (n={len(correlation_data)})")
        
        # Stw√≥rz wykres korelacji
        create_correlation_scatter(correlation_data, migr_col, bezr_col, year, migr_type, correlation)
        
        return {
            'year': year,
            'migration_type': migr_type,
            'correlation': correlation,
            'n_observations': len(correlation_data),
            'migration_mean': correlation_data[migr_col].mean(),
            'migration_std': correlation_data[migr_col].std(),
            'unemployment_mean': correlation_data[bezr_col].mean(),
            'unemployment_std': correlation_data[bezr_col].std(),
            'comparison_variable': 'bezrobocie'
        }
        
    except Exception as e:
        print(f"  B≈ÇƒÖd przy obliczaniu korelacji {migr_type} vs bezrobocie: {e}")
        return None

def create_correlation_scatter(data: Any, migr_col: str, bezr_col: str, year: int, migr_type: str, correlation: float) -> None:
    """Tworzy wykres punktowy korelacji."""
    plt.figure(figsize=(8, 6))
    plt.scatter(data[migr_col], data[bezr_col], alpha=0.6, s=30)
    plt.xlabel(f'{migr_type.title()} (people)', fontsize=12)
    plt.ylabel('Unemployment per 1000 people', fontsize=12)
    plt.title(f'Correlation {migr_type} vs unemployment {year}', fontsize=14, fontweight='bold')
    plt.grid(True, alpha=0.3)
    
    # Dodaj informacjƒô o korelacji
    plt.text(0.05, 0.95, f'r = {correlation:.3f}\nn = {len(data)}', 
             transform=plt.gca().transAxes, fontsize=12, 
             bbox=dict(boxstyle="round,pad=0.3", facecolor="white", alpha=0.8),
             verticalalignment='top')
    
    plt.tight_layout()
    os.makedirs('korelacje', exist_ok=True)
    plt.savefig(f'korelacje/korelacja_{migr_type}_{year}.png', dpi=150, bbox_inches='tight')
    plt.close()
    print(f"  Zapisano wykres korelacji: korelacje/korelacja_{migr_type}_{year}.png")

def save_correlation_results(correlation_results: List[Dict[str, Any]]) -> None:
    """Zapisuje wyniki korelacji do pliku CSV."""
    df = pd.DataFrame(correlation_results)
    df = df.round(3)
    df.to_csv('wyniki_korelacji.csv', index=False)
    print(f"\nZapisano wyniki korelacji do pliku: wyniki_korelacji.csv")
    print("Podsumowanie korelacji:")
    print(df.groupby('migration_type')['correlation'].describe())

def create_correlation_plots(correlation_results: List[Dict[str, Any]]) -> None:
    """Tworzy wykresy pokazujƒÖce zmiany korelacji w czasie."""
    df = pd.DataFrame(correlation_results)
    
    # Wykres korelacji w czasie dla ka≈ºdego typu migracji
    plt.figure(figsize=(12, 8))
    
    migration_types = df['migration_type'].unique()
    colors = ['red', 'blue', 'green', 'orange', 'purple', 'brown', 'pink', 'gray']
    
    for i, migr_type in enumerate(migration_types):
        type_data = df[df['migration_type'] == migr_type]
        color = colors[i % len(colors)]  # Cykliczne u≈ºycie kolor√≥w
        plt.plot(type_data['year'], type_data['correlation'], 
                marker='o', label=migr_type.title(), color=color, linewidth=2)
    
    plt.xlabel('Rok', fontsize=12)
    plt.ylabel('Korelacja z bezrobociem', fontsize=12)
    plt.title('Korelacja miƒôdzy migracjami a bezrobociem w czasie', fontsize=14, fontweight='bold')
    plt.legend()
    plt.grid(True, alpha=0.3)
    plt.axhline(y=0, color='black', linestyle='--', alpha=0.5)
    
    plt.tight_layout()
    plt.savefig('korelacje_w_czasie.png', dpi=150, bbox_inches='tight')
    plt.close()
    print("Zapisano wykres korelacji w czasie: korelacje_w_czasie.png")

def create_advanced_migration_visualizations(map_visualizer: MapVisualizer, mapa: Any, data_loader: DataLoader):
    """Tworzy zaawansowane wizualizacje migracji: flow maps, hot spots i animacje."""
    
    # Stw√≥rz foldery na r√≥≈ºne typy wizualizacji
    os.makedirs('mapy/flow_maps', exist_ok=True)
    os.makedirs('mapy/hotspots', exist_ok=True)
    os.makedirs('mapy/animations', exist_ok=True)
    
    # Zbierz dane migracji dla wszystkich lat
    migration_data_dict = {}
    years_list = list(range(2005, 2024))
    
    print("Zbieranie danych migracji dla wszystkich lat...")
    for year in years_list:
        migr_data, _, _ = data_loader.get_data_for_year(year)
        if migr_data is not None:
            migration_cols = data_loader.get_migration_columns_for_year(year)
            if 'saldo' in migration_cols:
                migration_data_dict[year] = migr_data
                print(f"  Rok {year}: {len(migr_data)} rekord√≥w")
    
    if not migration_data_dict:
        print("Brak danych migracji do zaawansowanych wizualizacji")
        return
    
    print(f"Zebrano dane dla {len(migration_data_dict)} lat: {list(migration_data_dict.keys())}")
    
    # 1. FLOW MAPS - mapy przep≈Çyw√≥w dla wybranych lat
    print("\n1. Tworzenie map przep≈Çyw√≥w (Flow Maps)...")
    sample_years = [2008, 2012, 2016, 2020, 2023]  # Reprezentatywne lata
    
    for year in sample_years:
        if year in migration_data_dict:
            migr_data = migration_data_dict[year]
            migration_cols = data_loader.get_migration_columns_for_year(year)
            
            if 'saldo' in migration_cols:
                print(f"  Tworzenie flow map dla roku {year}...")
                
                # Tw√≥rz standardowƒÖ flow map
                map_visualizer.create_flow_map(
                    mapa,
                    year,
                    f'Migration flows {year}',
                    f'mapy/flow_maps/flow_map_{year}.png',
                    migr_data,
                    migration_cols['saldo'],
                    flow_threshold=0.1
                )
                
                # Tw√≥rz r√≥wnie≈º flow map z ni≈ºszym progiem (wiƒôcej strza≈Çek)
                map_visualizer.create_flow_map(
                    mapa,
                    year,
                    f'Migration flows {year} (detailed)',
                    f'mapy/flow_maps/flow_map_detailed_{year}.png',
                    migr_data,
                    migration_cols['saldo'],
                    flow_threshold=0.05  # Ni≈ºszy pr√≥g = wiƒôcej strza≈Çek
                )
    
    # 2. HOT SPOT ANALYSIS - analiza hot spot√≥w dla wybranych lat
    print("\n2. Tworzenie map hot spot√≥w...")
    
    for year in sample_years:
        if year in migration_data_dict:
            migr_data = migration_data_dict[year]
            migration_cols = data_loader.get_migration_columns_for_year(year)
            
            if 'saldo' in migration_cols:
                print(f"  Tworzenie hot spot map dla roku {year}...")
                map_visualizer.create_hotspot_map(
                    mapa,
                    year,
                    f'Migration hot spots {year}',
                    f'mapy/hotspots/hotspots_{year}.png',
                    migr_data,
                    migration_cols['saldo'],
                    hotspot_threshold=1.5
                )
    
    # 3. ANIMACJE CZASOWE
    print("\n3. Tworzenie animacji czasowych...")
    
    # Animacja choropleth (mapa kolorowa)
    print("  Tworzenie animacji choropleth...")
    try:
        # Przygotuj dane z kolumnƒÖ saldo dla wszystkich lat
        animation_data_dict = {}
        for year, migr_data in migration_data_dict.items():
            migration_cols = data_loader.get_migration_columns_for_year(year)
            if 'saldo' in migration_cols:
                # Dodaj kolumnƒô 'saldo' do danych
                migr_data_copy = migr_data.copy()
                migr_data_copy['saldo'] = migr_data_copy[migration_cols['saldo']]
                animation_data_dict[year] = migr_data_copy
        
        if animation_data_dict:
            map_visualizer.create_time_animation(
                mapa,
                list(animation_data_dict.keys()),
                'Migration changes over time (2005-2023)',
                'mapy/animations/migration_choropleth_animation.gif',
                animation_data_dict,
                'saldo',
                animation_type='choropleth',
                data_type='migration'
            )
    except Exception as e:
        print(f"  B≈ÇƒÖd przy tworzeniu animacji choropleth: {e}")
    
    # Animacja flow (przep≈Çywy)
    print("  Tworzenie animacji przep≈Çyw√≥w...")
    try:
        # Sprawd≈∫ czy animation_data_dict istnieje i ma dane
        if 'animation_data_dict' in locals() and animation_data_dict:
            map_visualizer.create_time_animation(
                mapa,
                list(animation_data_dict.keys()),
                'Migration flow changes over time (2005-2023)',
                'mapy/animations/migration_flow_animation.gif',
                animation_data_dict,
                'saldo',
                animation_type='flow',
                data_type='migration'
            )
        else:
            print("  Brak danych do animacji przep≈Çyw√≥w")
    except Exception as e:
        print(f"  B≈ÇƒÖd przy tworzeniu animacji przep≈Çyw√≥w: {e}")
    
    # 4. ANALIZA POR√ìWNAWCZA - por√≥wnanie r√≥≈ºnych okres√≥w
    print("\n4. Tworzenie map por√≥wnawczych...")
    
    # Por√≥wnanie przed i po kryzysie finansowym (2007 vs 2010)
    if 2007 in migration_data_dict and 2010 in migration_data_dict:
        create_comparison_maps(map_visualizer, mapa, migration_data_dict, data_loader, 
                             2007, 2010, "Before and after financial crisis")
    
    # Por√≥wnanie przed i po COVID (2019 vs 2021)
    if 2019 in migration_data_dict and 2021 in migration_data_dict:
        create_comparison_maps(map_visualizer, mapa, migration_data_dict, data_loader, 
                             2019, 2021, "Before and after COVID-19")
    
    print("\n=== Zako≈Ñczono tworzenie zaawansowanych wizualizacji ===")

def create_unemployment_animations(map_visualizer: MapVisualizer, mapa: Any, data_loader: DataLoader):
    """Tworzy animacje czasowe dla danych bezrobocia."""
    print("\n=== Tworzenie animacji bezrobocia ===")
    
    # Przygotuj dane bezrobocia dla animacji
    unemployment_data_dict = {}
    
    for year in range(2005, 2024):
        print(f"  ≈Åadowanie danych bezrobocia dla roku {year}...")
        try:
            _, bezr_data, _ = data_loader.get_data_for_year(year)
            if bezr_data is not None and len(bezr_data) > 0:
                # Dodaj kolumnƒô bezrobocie_na_1000 je≈õli nie istnieje
                if 'bezrobocie_na_1000' not in bezr_data.columns:
                    if 'bezrobocie' in bezr_data.columns and 'ludnosc' in bezr_data.columns:
                        bezr_data['bezrobocie_na_1000'] = (bezr_data['bezrobocie'] / bezr_data['ludnosc']) * 1000
                    else:
                        print(f"    Brak wymaganych kolumn dla roku {year}")
                        continue
                
                unemployment_data_dict[year] = bezr_data
            else:
                print(f"    Brak danych bezrobocia dla roku {year}")
        except Exception as e:
            print(f"    B≈ÇƒÖd przy ≈Çadowaniu danych bezrobocia dla roku {year}: {e}")
    
    if not unemployment_data_dict:
        print("  Brak danych bezrobocia do animacji")
        return
    
    print(f"  Przygotowano dane bezrobocia dla {len(unemployment_data_dict)} lat")
    
    # Animacja choropleth bezrobocia
    print("  Tworzenie animacji choropleth bezrobocia...")
    try:
        os.makedirs('mapy/animations', exist_ok=True)
        map_visualizer.create_time_animation(
            mapa,
            list(unemployment_data_dict.keys()),
            'Unemployment changes over time (2005-2023)',
            'mapy/animations/unemployment_choropleth_animation.gif',
            unemployment_data_dict,
            'bezrobocie_na_1000',
            animation_type='choropleth',
            data_type='unemployment'
        )
    except Exception as e:
        print(f"  B≈ÇƒÖd przy tworzeniu animacji choropleth bezrobocia: {e}")
    
    print("=== Zako≈Ñczono tworzenie animacji bezrobocia ===")

def test_animation_legends():
    """Funkcja testowa do sprawdzenia czy legendy w animacjach dzia≈ÇajƒÖ poprawnie."""
    print("\n=== Test legend w animacjach ===")
    
    try:
        from analysis_urban_poland.map_loader import MapLoader
        from analysis_urban_poland.legend_calculator import LegendCalculator
        
        # Inicjalizuj komponenty
        legend_calculator = LegendCalculator()
        map_loader = MapLoader()
        map_visualizer = MapVisualizer(legend_calculator)
        
        # Pobierz mapƒô dla najnowszego roku
        mapa = map_loader.get_map_for_year(2023)
        if mapa is None:
            print("  Nie uda≈Ço siƒô wczytaƒá mapy testowej")
            return
        
        # Stw√≥rz testowe dane migracji
        test_migration_data = {}
        for year in [2020, 2021, 2022]:
            # Stw√≥rz losowe dane migracji dla pierwszych 50 gmin
            sample_codes = mapa['Kod'].head(50).tolist()
            np.random.seed(year)  # Dla powtarzalno≈õci
            
            test_data = pd.DataFrame({
                'Kod': sample_codes,
                'saldo': np.random.normal(0, 50, len(sample_codes))  # ≈örednia 0, odchylenie 50
            })
            test_migration_data[year] = test_data
        
        # Stw√≥rz testowe dane bezrobocia
        test_unemployment_data = {}
        for year in [2020, 2021, 2022]:
            sample_codes = mapa['Kod'].head(50).tolist()
            np.random.seed(year + 100)  # Inne ziarno dla bezrobocia
            
            test_data = pd.DataFrame({
                'Kod': sample_codes,
                'bezrobocie_na_1000': np.random.uniform(15, 60, len(sample_codes))  # Od 15 do 60
            })
            test_unemployment_data[year] = test_data
        
        # Test animacji migracji
        print("  Tworzenie testowej animacji migracji...")
        os.makedirs('mapy/test_animations', exist_ok=True)
        
        map_visualizer.create_time_animation(
            mapa,
            [2020, 2021, 2022],
            'TEST: Animacja migracji z poprawionƒÖ legendƒÖ',
            'mapy/test_animations/test_migration_animation.gif',
            test_migration_data,
            'saldo',
            animation_type='choropleth',
            data_type='migration'
        )
        
        # Test animacji bezrobocia
        print("  Tworzenie testowej animacji bezrobocia...")
        
        map_visualizer.create_time_animation(
            mapa,
            [2020, 2021, 2022],
            'TEST: Animacja bezrobocia z poprawionƒÖ legendƒÖ',
            'mapy/test_animations/test_unemployment_animation.gif',
            test_unemployment_data,
            'bezrobocie_na_1000',
            animation_type='choropleth',
            data_type='unemployment'
        )
        
        print("‚úÖ Test animacji zako≈Ñczony pomy≈õlnie!")
        print("üìÅ Sprawd≈∫ wyniki w folderze: mapy/test_animations/")
        print("üîç Sprawd≈∫ czy:")
        print("   ‚Ä¢ Legenda migracji ma zakres od ujemnych do dodatnich warto≈õci")
        print("   ‚Ä¢ Legenda bezrobocia ma zakres od ma≈Çych do du≈ºych warto≈õci (tylko dodatnie)")
        print("   ‚Ä¢ Znaczniki na legendzie sƒÖ r√≥wnomiernie roz≈Ço≈ºone")
        print("   ‚Ä¢ Kolory odpowiadajƒÖ rzeczywistym warto≈õciom danych")
        
    except Exception as e:
        print(f"‚ùå B≈ÇƒÖd w te≈õcie animacji: {e}")
    
    print("=== Koniec testu legend ===")

def create_comparison_maps(map_visualizer: MapVisualizer, mapa: Any, 
                          migration_data_dict: Dict[int, Any], data_loader: DataLoader,
                          year1: int, year2: int, comparison_name: str):
    """Tworzy mapy por√≥wnawcze miƒôdzy dwoma latami."""
    print(f"  Por√≥wnanie {year1} vs {year2}: {comparison_name}")
    
    # Pobierz dane dla obu lat
    migr_data1 = migration_data_dict[year1]
    migr_data2 = migration_data_dict[year2]
    
    migration_cols1 = data_loader.get_migration_columns_for_year(year1)
    migration_cols2 = data_loader.get_migration_columns_for_year(year2)
    
    if 'saldo' not in migration_cols1 or 'saldo' not in migration_cols2:
        print(f"    Brak danych saldo dla por√≥wnania {year1} vs {year2}")
        return
    
    # Po≈ÇƒÖcz dane z mapƒÖ
    merged1 = mapa.merge(migr_data1, on='Kod', how='inner')
    merged2 = mapa.merge(migr_data2, on='Kod', how='inner')
    
    # Oblicz r√≥≈ºnicƒô miƒôdzy latami
    common_codes = set(merged1['Kod']) & set(merged2['Kod'])
    if len(common_codes) < 10:
        print(f"    Zbyt ma≈Ço wsp√≥lnych obszar√≥w dla por√≥wnania {year1} vs {year2}")
        return
    
    # Stw√≥rz dataframe z r√≥≈ºnicami
    comparison_data = []
    for kod in common_codes:
        val1 = merged1[merged1['Kod'] == kod][migration_cols1['saldo']].iloc[0]
        val2 = merged2[merged2['Kod'] == kod][migration_cols2['saldo']].iloc[0]
        
        if pd.notna(val1) and pd.notna(val2):
            # Pobierz geometriƒô z oryginalnej mapy (nie z merged, ≈ºeby uniknƒÖƒá duplikat√≥w)
            geometry = mapa[mapa['Kod'] == kod]['geometry'].iloc[0]
            comparison_data.append({
                'Kod': kod,
                'roznica_saldo': val2 - val1,
                'geometry': geometry
            })
    
    if len(comparison_data) < 10:
        print(f"    Zbyt ma≈Ço prawid≈Çowych danych dla por√≥wnania {year1} vs {year2}")
        return
    
    comparison_df = pd.DataFrame(comparison_data)
    comparison_gdf = gpd.GeoDataFrame(comparison_df, geometry='geometry')
    
    # Tw√≥rz mapƒô r√≥≈ºnic
    os.makedirs('mapy/comparisons', exist_ok=True)
    
    # Mapa hot spot√≥w r√≥≈ºnic
    map_visualizer.create_hotspot_map(
        mapa,
        year2,  # U≈ºyj p√≥≈∫niejszego roku jako referencyjnego
        f'Migration changes: {comparison_name} ({year1} ‚Üí {year2})',
        f'mapy/comparisons/comparison_hotspots_{year1}_{year2}.png',
        comparison_gdf,
        'roznica_saldo',
        hotspot_threshold=1.0
    )
    
    # Mapa flow r√≥≈ºnic
    map_visualizer.create_flow_map(
        mapa,
        year2,
        f'Migration flow changes: {comparison_name} ({year1} ‚Üí {year2})',
        f'mapy/comparisons/comparison_flow_{year1}_{year2}.png',
        comparison_gdf,
        'roznica_saldo',
        flow_threshold=0.2
    )

def perform_advanced_migration_unemployment_analysis(mapa_migr: Any, mapa_bezr: Any, 
                                                   migr_col: str, bezr_col: str, 
                                                   year: int, migr_type: str) -> Optional[Dict[str, Any]]:
    """Przeprowadza zaawansowanƒÖ analizƒô przyczynowo-skutkowƒÖ miƒôdzy migracjƒÖ a bezrobociem."""
    try:
        # Po≈ÇƒÖcz dane migracji i bezrobocia
        analysis_data = mapa_migr[['Kod', migr_col]].merge(
            mapa_bezr[['Kod', bezr_col]], on='Kod', how='inner'
        )
        
        # Usu≈Ñ brakujƒÖce warto≈õci
        analysis_data = analysis_data.dropna()
        
        if len(analysis_data) < 20:  # Minimum 20 obserwacji dla wiarygodnej analizy
            print(f"  Zbyt ma≈Ço danych dla analizy {migr_type} vs bezrobocie ({len(analysis_data)} obserwacji)")
            return None
        
        migration_values = analysis_data[migr_col].values
        unemployment_values = analysis_data[bezr_col].values
        
        # 1. ANALIZA KIERUNKU MIGRACJI W ZALE≈ªNO≈öCI OD BEZROBOCIA
        high_unemployment_threshold = np.percentile(unemployment_values, 75)  # G√≥rny kwartyl
        low_unemployment_threshold = np.percentile(unemployment_values, 25)   # Dolny kwartyl
        
        high_unemployment_mask = unemployment_values >= high_unemployment_threshold
        low_unemployment_mask = unemployment_values <= low_unemployment_threshold
        
        # ≈örednie saldo migracji w regionach o wysokim i niskim bezrobociu
        avg_migration_high_unemployment = np.mean(migration_values[high_unemployment_mask])
        avg_migration_low_unemployment = np.mean(migration_values[low_unemployment_mask])
        
        # 2. ANALIZA PRZYCIƒÑGANIA MIGRACYJNEGO
        positive_migration_mask = migration_values > 0  # Regiony z nap≈Çywem
        negative_migration_mask = migration_values < 0  # Regiony z odp≈Çywem
        
        avg_unemployment_positive_migration = np.mean(unemployment_values[positive_migration_mask])
        avg_unemployment_negative_migration = np.mean(unemployment_values[negative_migration_mask])
        
        # 3. KLASYFIKACJA REGION√ìW
        # Regiony atrakcyjne: niskie bezrobocie + dodatnia migracja
        attractive_regions = (unemployment_values <= low_unemployment_threshold) & (migration_values > 0)
        
        # Regiony odpychajƒÖce: wysokie bezrobocie + ujemna migracja
        repulsive_regions = (unemployment_values >= high_unemployment_threshold) & (migration_values < 0)
        
        # Regiony paradoksalne: wysokie bezrobocie + dodatnia migracja
        paradoxical_regions = (unemployment_values >= high_unemployment_threshold) & (migration_values > 0)
        
        # Regiony stagnacyjne: niskie bezrobocie + ujemna migracja
        stagnant_regions = (unemployment_values <= low_unemployment_threshold) & (migration_values < 0)
        
        # 4. OBLICZ WSKA≈πNIKI
        correlation = np.corrcoef(migration_values, unemployment_values)[0, 1]
        
        # Si≈Ça odpychania (jak bardzo wysokie bezrobocie koreluje z odp≈Çywem)
        repulsion_strength = avg_migration_high_unemployment
        
        # Si≈Ça przyciƒÖgania (jak bardzo niskie bezrobocie koreluje z nap≈Çywem)
        attraction_strength = avg_migration_low_unemployment
        
        # Efektywno≈õƒá rynku pracy (r√≥≈ºnica miƒôdzy atrakcyjno≈õciƒÖ a odpychaniem)
        labor_market_efficiency = attraction_strength - repulsion_strength
        
        # 5. STW√ìRZ WIZUALIZACJƒò ANALIZY
        create_advanced_analysis_visualization(analysis_data, migr_col, bezr_col, year, migr_type,
                                             high_unemployment_threshold, low_unemployment_threshold,
                                             attractive_regions, repulsive_regions, 
                                             paradoxical_regions, stagnant_regions)
        
        print(f"  === ANALIZA PRZYCZYNOWO-SKUTKOWA {migr_type.upper()} vs BEZROBOCIE {year} ===")
        print(f"  üìä Regiony atrakcyjne (niskie bezrobocie + nap≈Çyw): {np.sum(attractive_regions)} ({np.sum(attractive_regions)/len(analysis_data)*100:.1f}%)")
        print(f"  üìâ Regiony odpychajƒÖce (wysokie bezrobocie + odp≈Çyw): {np.sum(repulsive_regions)} ({np.sum(repulsive_regions)/len(analysis_data)*100:.1f}%)")
        print(f"  ‚ö†Ô∏è  Regiony paradoksalne (wysokie bezrobocie + nap≈Çyw): {np.sum(paradoxical_regions)} ({np.sum(paradoxical_regions)/len(analysis_data)*100:.1f}%)")
        print(f"  üîÑ Regiony stagnacyjne (niskie bezrobocie + odp≈Çyw): {np.sum(stagnant_regions)} ({np.sum(stagnant_regions)/len(analysis_data)*100:.1f}%)")
        print(f"  üí™ Si≈Ça przyciƒÖgania: {attraction_strength:.2f}")
        print(f"  üí® Si≈Ça odpychania: {repulsion_strength:.2f}")
        print(f"  ‚öñÔ∏è  Efektywno≈õƒá rynku pracy: {labor_market_efficiency:.2f}")
        print(f"  üîó Korelacja: {correlation:.3f}")
        
        return {
            'year': year,
            'migration_type': migr_type,
            'correlation': correlation,
            'n_observations': len(analysis_data),
            'attractive_regions_count': np.sum(attractive_regions),
            'repulsive_regions_count': np.sum(repulsive_regions),
            'paradoxical_regions_count': np.sum(paradoxical_regions),
            'stagnant_regions_count': np.sum(stagnant_regions),
            'attractive_regions_pct': np.sum(attractive_regions)/len(analysis_data)*100,
            'repulsive_regions_pct': np.sum(repulsive_regions)/len(analysis_data)*100,
            'paradoxical_regions_pct': np.sum(paradoxical_regions)/len(analysis_data)*100,
            'stagnant_regions_pct': np.sum(stagnant_regions)/len(analysis_data)*100,
            'attraction_strength': attraction_strength,
            'repulsion_strength': repulsion_strength,
            'labor_market_efficiency': labor_market_efficiency,
            'avg_migration_high_unemployment': avg_migration_high_unemployment,
            'avg_migration_low_unemployment': avg_migration_low_unemployment,
            'avg_unemployment_positive_migration': avg_unemployment_positive_migration,
            'avg_unemployment_negative_migration': avg_unemployment_negative_migration,
            'high_unemployment_threshold': high_unemployment_threshold,
            'low_unemployment_threshold': low_unemployment_threshold,
            'comparison_variable': 'bezrobocie'
        }
        
    except Exception as e:
        print(f"  B≈ÇƒÖd przy analizie {migr_type} vs bezrobocie: {e}")
        return None

def create_advanced_analysis_visualization(data: Any, migr_col: str, bezr_col: str, 
                                         year: int, migr_type: str,
                                         high_unemployment_threshold: float, 
                                         low_unemployment_threshold: float,
                                         attractive_regions: Any, repulsive_regions: Any,
                                         paradoxical_regions: Any, stagnant_regions: Any):
    """Tworzy zaawansowanƒÖ wizualizacjƒô analizy przyczynowo-skutkowej."""
    
    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(16, 12))
    
    migration_values = data[migr_col].values
    unemployment_values = data[bezr_col].values
    
    # 1. Wykres punktowy z klasyfikacjƒÖ region√≥w
    ax1.scatter(unemployment_values[attractive_regions], migration_values[attractive_regions], 
               c='green', alpha=0.7, s=50, label=f'Atrakcyjne (n={np.sum(attractive_regions)})')
    ax1.scatter(unemployment_values[repulsive_regions], migration_values[repulsive_regions], 
               c='red', alpha=0.7, s=50, label=f'OdpychajƒÖce (n={np.sum(repulsive_regions)})')
    ax1.scatter(unemployment_values[paradoxical_regions], migration_values[paradoxical_regions], 
               c='orange', alpha=0.7, s=50, label=f'Paradoksalne (n={np.sum(paradoxical_regions)})')
    ax1.scatter(unemployment_values[stagnant_regions], migration_values[stagnant_regions], 
               c='gray', alpha=0.7, s=50, label=f'Stagnacyjne (n={np.sum(stagnant_regions)})')
    
    # Dodaj linie progowe
    ax1.axvline(high_unemployment_threshold, color='red', linestyle='--', alpha=0.5, label='Pr√≥g wysokiego bezrobocia')
    ax1.axvline(low_unemployment_threshold, color='green', linestyle='--', alpha=0.5, label='Pr√≥g niskiego bezrobocia')
    ax1.axhline(0, color='black', linestyle='-', alpha=0.3)
    
    ax1.set_xlabel('Unemployment per 1000 people', fontsize=12)
    ax1.set_ylabel(f'{migr_type.title()} (people)', fontsize=12)
    ax1.set_title(f'Region classification {year}', fontsize=14, fontweight='bold')
    ax1.legend()
    ax1.grid(True, alpha=0.3)
    
    # 2. Histogram bezrobocia z podzia≈Çem na regiony
    bins = np.linspace(unemployment_values.min(), unemployment_values.max(), 20)
    ax2.hist(unemployment_values[migration_values > 0], bins=bins, alpha=0.7, 
            label=f'Inflow (n={np.sum(migration_values > 0)})', color='blue')
    ax2.hist(unemployment_values[migration_values < 0], bins=bins, alpha=0.7, 
            label=f'Outflow (n={np.sum(migration_values < 0)})', color='red')
    ax2.set_xlabel('Unemployment per 1000 people', fontsize=12)
    ax2.set_ylabel('Number of regions', fontsize=12)
    ax2.set_title('Unemployment distribution by migration direction', fontsize=14, fontweight='bold')
    ax2.legend()
    ax2.grid(True, alpha=0.3)
    
    # 3. ≈örednie warto≈õci w r√≥≈ºnych kategoriach
    categories = ['Attractive', 'Repulsive', 'Paradoxical', 'Stagnant']
    migration_means = [
        np.mean(migration_values[attractive_regions]) if np.sum(attractive_regions) > 0 else 0,
        np.mean(migration_values[repulsive_regions]) if np.sum(repulsive_regions) > 0 else 0,
        np.mean(migration_values[paradoxical_regions]) if np.sum(paradoxical_regions) > 0 else 0,
        np.mean(migration_values[stagnant_regions]) if np.sum(stagnant_regions) > 0 else 0
    ]
    unemployment_means = [
        np.mean(unemployment_values[attractive_regions]) if np.sum(attractive_regions) > 0 else 0,
        np.mean(unemployment_values[repulsive_regions]) if np.sum(repulsive_regions) > 0 else 0,
        np.mean(unemployment_values[paradoxical_regions]) if np.sum(paradoxical_regions) > 0 else 0,
        np.mean(unemployment_values[stagnant_regions]) if np.sum(stagnant_regions) > 0 else 0
    ]
    
    colors = ['green', 'red', 'orange', 'gray']
    bars = ax3.bar(categories, migration_means, color=colors, alpha=0.7)
    ax3.set_ylabel(f'Average {migr_type}', fontsize=12)
    ax3.set_title('Average migration by region type', fontsize=14, fontweight='bold')
    ax3.grid(True, alpha=0.3, axis='y')
    
    # Dodaj warto≈õci na s≈Çupkach
    for bar, value in zip(bars, migration_means):
        height = bar.get_height()
        ax3.text(bar.get_x() + bar.get_width()/2., height + (max(migration_means) - min(migration_means))*0.01,
                f'{value:.1f}', ha='center', va='bottom', fontweight='bold')
    
    # 4. ≈örednie bezrobocie wed≈Çug typu regionu
    bars2 = ax4.bar(categories, unemployment_means, color=colors, alpha=0.7)
    ax4.set_ylabel('Average unemployment per 1000 people', fontsize=12)
    ax4.set_title('Average unemployment by region type', fontsize=14, fontweight='bold')
    ax4.grid(True, alpha=0.3, axis='y')
    
    # Dodaj warto≈õci na s≈Çupkach
    for bar, value in zip(bars2, unemployment_means):
        height = bar.get_height()
        ax4.text(bar.get_x() + bar.get_width()/2., height + (max(unemployment_means) - min(unemployment_means))*0.01,
                f'{value:.1f}', ha='center', va='bottom', fontweight='bold')
    
    plt.tight_layout()
    os.makedirs('analizy_przyczynowe', exist_ok=True)
    plt.savefig(f'analizy_przyczynowe/analiza_przyczynowa_{migr_type}_{year}.png', dpi=150, bbox_inches='tight')
    plt.close()
    print(f"  Zapisano analizƒô przyczynowƒÖ: analizy_przyczynowe/analiza_przyczynowa_{migr_type}_{year}.png")

def perform_temporal_causality_analysis(correlation_results: List[Dict[str, Any]]) -> None:
    """Przeprowadza analizƒô czasowƒÖ sprawdzajƒÖcƒÖ zwiƒÖzek przyczynowo-skutkowy miƒôdzy bezrobociem a migracjƒÖ w czasie."""
    df = pd.DataFrame(correlation_results)
    
    print("\n" + "="*80)
    print("üïê ANALIZA CZASOWA - CO BY≈ÅO PIERWSZE: BEZROBOCIE CZY MIGRACJA?")
    print("="*80)
    
    # Analiza trend√≥w w czasie
    years = sorted(df['year'].unique())
    
    # Grupuj dane wed≈Çug typu migracji
    migration_types = df['migration_type'].unique()
    
    fig, axes = plt.subplots(2, 2, figsize=(16, 12))
    fig.suptitle('Analiza czasowa zwiƒÖzk√≥w przyczynowo-skutkowych', fontsize=16, fontweight='bold')
    
    colors = ['red', 'blue', 'green', 'orange', 'purple', 'brown', 'pink', 'gray']
    
    # 1. Korelacje w czasie
    ax1 = axes[0, 0]
    for i, migr_type in enumerate(migration_types):
        type_data = df[df['migration_type'] == migr_type].sort_values('year')
        if len(type_data) > 2:  # Tylko je≈õli mamy przynajmniej 3 punkty danych
            color = colors[i % len(colors)]
            ax1.plot(type_data['year'], type_data['correlation'], 
                    marker='o', label=migr_type.title(), color=color, linewidth=2)
    
    ax1.set_xlabel('Rok')
    ax1.set_ylabel('Korelacja z bezrobociem')
    ax1.set_title('Korelacja migracja-bezrobocie w czasie')
    ax1.legend()
    ax1.grid(True, alpha=0.3)
    ax1.axhline(y=0, color='black', linestyle='--', alpha=0.5)
    
    # 2. Efektywno≈õƒá rynku pracy w czasie
    ax2 = axes[0, 1]
    for i, migr_type in enumerate(migration_types):
        type_data = df[df['migration_type'] == migr_type].sort_values('year')
        if len(type_data) > 2 and 'labor_market_efficiency' in type_data.columns:
            color = colors[i % len(colors)]
            ax2.plot(type_data['year'], type_data['labor_market_efficiency'], 
                    marker='s', label=migr_type.title(), color=color, linewidth=2)
    
    ax2.set_xlabel('Rok')
    ax2.set_ylabel('Efektywno≈õƒá rynku pracy')
    ax2.set_title('Efektywno≈õƒá rynku pracy w czasie')
    ax2.legend()
    ax2.grid(True, alpha=0.3)
    ax2.axhline(y=0, color='black', linestyle='--', alpha=0.5)
    
    # 3. Regiony atrakcyjne vs odpychajƒÖce w czasie
    ax3 = axes[1, 0]
    avg_attractive = df.groupby('year')['attractive_regions_pct'].mean()
    avg_repulsive = df.groupby('year')['repulsive_regions_pct'].mean()
    
    ax3.plot(avg_attractive.index, avg_attractive.values, 
            marker='o', label='Regiony atrakcyjne (%)', color='green', linewidth=3)
    ax3.plot(avg_repulsive.index, avg_repulsive.values, 
            marker='s', label='Regiony odpychajƒÖce (%)', color='red', linewidth=3)
    
    ax3.set_xlabel('Rok')
    ax3.set_ylabel('Procent region√≥w')
    ax3.set_title('Dynamika region√≥w atrakcyjnych vs odpychajƒÖcych')
    ax3.legend()
    ax3.grid(True, alpha=0.3)
    
    # 4. Analiza okres√≥w kryzysowych
    ax4 = axes[1, 1]
    
    # Identyfikuj okresy kryzysowe
    crisis_periods = [
        (2008, 2010, 'Kryzys finansowy', 'red'),
        (2020, 2021, 'COVID-19', 'orange')
    ]
    
    # ≈örednia korelacja w czasie
    avg_correlation = df.groupby('year')['correlation'].mean()
    ax4.plot(avg_correlation.index, avg_correlation.values, 
            marker='o', color='blue', linewidth=3, label='≈örednia korelacja')
    
    # Zaznacz okresy kryzysowe
    for start_year, end_year, label, color in crisis_periods:
        ax4.axvspan(start_year, end_year, alpha=0.2, color=color, label=label)
    
    ax4.set_xlabel('Rok')
    ax4.set_ylabel('≈örednia korelacja')
    ax4.set_title('Wp≈Çyw kryzys√≥w na zwiƒÖzek bezrobocie-migracja')
    ax4.legend()
    ax4.grid(True, alpha=0.3)
    ax4.axhline(y=0, color='black', linestyle='--', alpha=0.5)
    
    plt.tight_layout()
    plt.savefig('analiza_czasowa_przyczynowosci.png', dpi=150, bbox_inches='tight')
    plt.close()
    print("üìä Zapisano analizƒô czasowƒÖ: analiza_czasowa_przyczynowosci.png")
    
    # ANALIZA STATYSTYCZNA TREND√ìW
    print("\nüìà ANALIZA TREND√ìW CZASOWYCH:")
    
    for migr_type in migration_types:
        type_data = df[df['migration_type'] == migr_type].sort_values('year')
        if len(type_data) >= 5:  # Przynajmniej 5 lat danych
            correlations = type_data['correlation'].values
            years_subset = type_data['year'].values
            
            # Oblicz trend (regresja liniowa)
            if len(correlations) > 1:
                trend_coef = np.polyfit(years_subset, correlations, 1)[0]
                
                print(f"  {migr_type.title()}:")
                print(f"    üìä Trend korelacji: {trend_coef:.4f}/rok")
                
                if abs(trend_coef) > 0.01:
                    if trend_coef > 0:
                        print(f"    üìà RosnƒÖcy zwiƒÖzek bezrobocie-migracja (wzmacnianie siƒô zale≈ºno≈õci)")
                    else:
                        print(f"    üìâ S≈ÇabnƒÖcy zwiƒÖzek bezrobocie-migracja (os≈Çabianie siƒô zale≈ºno≈õci)")
                else:
                    print(f"    ‚û°Ô∏è  Stabilny zwiƒÖzek bezrobocie-migracja")
                
                # Analiza okres√≥w przed i po kryzysach
                pre_crisis_data = type_data[type_data['year'] < 2008]
                crisis_data = type_data[(type_data['year'] >= 2008) & (type_data['year'] <= 2010)]
                post_crisis_data = type_data[type_data['year'] > 2010]
                covid_data = type_data[type_data['year'] >= 2020]
                
                if len(pre_crisis_data) > 0 and len(post_crisis_data) > 0:
                    pre_crisis_corr = pre_crisis_data['correlation'].mean()
                    post_crisis_corr = post_crisis_data['correlation'].mean()
                    crisis_impact = post_crisis_corr - pre_crisis_corr
                    
                    print(f"    üè¶ Wp≈Çyw kryzysu finansowego: {crisis_impact:+.3f}")
                    
                if len(covid_data) > 0 and len(post_crisis_data) > 0:
                    pre_covid_corr = post_crisis_data[post_crisis_data['year'] < 2020]['correlation'].mean()
                    covid_corr = covid_data['correlation'].mean()
                    covid_impact = covid_corr - pre_covid_corr
                    
                    print(f"    ü¶† Wp≈Çyw COVID-19: {covid_impact:+.3f}")
    
    # WNIOSKI PRZYCZYNOWE
    print("\nüéØ WNIOSKI PRZYCZYNOWE:")
    
    # Sprawd≈∫ czy regiony o wysokim bezrobociu majƒÖ ujemnƒÖ migracjƒô
    avg_repulsion = df['repulsion_strength'].mean()
    avg_attraction = df['attraction_strength'].mean()
    
    print(f"  üí® ≈örednia si≈Ça odpychania (wysokie bezrobocie): {avg_repulsion:.2f}")
    print(f"  üí™ ≈örednia si≈Ça przyciƒÖgania (niskie bezrobocie): {avg_attraction:.2f}")
    
    if avg_repulsion < -1 and avg_attraction > 1:
        print("  ‚úÖ POTWIERDZONO: Regiony z wysokim bezrobociem odpychajƒÖ mieszka≈Ñc√≥w")
        print("  ‚úÖ POTWIERDZONO: Regiony z niskim bezrobociem przyciƒÖgajƒÖ mieszka≈Ñc√≥w")
    elif avg_repulsion < 0 and avg_attraction > 0:
        print("  ‚ö†Ô∏è  CZƒò≈öCIOWO POTWIERDZONO: S≈Çaby efekt odpychania/przyciƒÖgania")
    else:
        print("  ‚ùå NIE POTWIERDZONO: Brak wyra≈∫nego wzorca migracji wzglƒôdem bezrobocia")
    
    # Analiza region√≥w paradoksalnych
    avg_paradoxical = df['paradoxical_regions_pct'].mean()
    print(f"  ü§î ≈örednio {avg_paradoxical:.1f}% region√≥w to regiony paradoksalne")
    print("     (wysokie bezrobocie + nap≈Çyw ludno≈õci)")
    
    if avg_paradoxical > 15:
        print("  ‚ö†Ô∏è  UWAGA: Du≈ºy odsetek region√≥w paradoksalnych - inne czynniki ni≈º bezrobocie")
        print("     wp≈ÇywajƒÖ na migracjƒô (np. infrastruktura, edukacja, kultura)")
    
    print("\n" + "="*80)

def create_analysis_summary(correlation_results: List[Dict[str, Any]]) -> None:
    """Tworzy podsumowanie analizy."""
    df = pd.DataFrame(correlation_results)
    
    print("\n" + "="*80)
    print("üìã RAPORT KO≈ÉCOWY - ANALIZA PRZYCZYNOWO-SKUTKOWA")
    print("="*80)
    
    # 1. OG√ìLNE STATYSTYKI
    print("\n1Ô∏è‚É£ OG√ìLNE STATYSTYKI:")
    print(f"   üìä Przeanalizowano {len(df)} przypadk√≥w")
    print(f"   üìÖ Lata: {df['year'].min()}-{df['year'].max()}")
    print(f"   üîÑ Typy migracji: {', '.join(df['migration_type'].unique())}")
    print(f"   üéØ ≈örednia liczba obserwacji na rok: {df['n_observations'].mean():.0f}")
    
    # 2. ANALIZA KORELACJI
    print("\n2Ô∏è‚É£ ANALIZA KORELACJI:")
    avg_correlation = df['correlation'].mean()
    print(f"   üìà ≈örednia korelacja: {avg_correlation:.3f}")
    
    if avg_correlation < -0.3:
        print("   ‚úÖ SILNA UJEMNA KORELACJA: Wysokie bezrobocie = odp≈Çyw ludno≈õci")
    elif avg_correlation < -0.1:
        print("   ‚ö†Ô∏è  S≈ÅABA UJEMNA KORELACJA: Czƒô≈õciowy wp≈Çyw bezrobocia na odp≈Çyw")
    elif avg_correlation > 0.1:
        print("   ‚ùì DODATNIA KORELACJA: Nieoczekiwany wzorzec - wymagane dalsze badania")
    else:
        print("   ‚û°Ô∏è  BRAK KORELACJI: Bezrobocie nie wp≈Çywa znaczƒÖco na migracjƒô")
    
    # 3. KLASYFIKACJA REGION√ìW
    print("\n3Ô∏è‚É£ KLASYFIKACJA REGION√ìW (≈õrednie warto≈õci):")
    print(f"   üü¢ Regiony atrakcyjne: {df['attractive_regions_pct'].mean():.1f}%")
    print(f"   üî¥ Regiony odpychajƒÖce: {df['repulsive_regions_pct'].mean():.1f}%")
    print(f"   üü† Regiony paradoksalne: {df['paradoxical_regions_pct'].mean():.1f}%")
    print(f"   üîò Regiony stagnacyjne: {df['stagnant_regions_pct'].mean():.1f}%")
    
    # 4. SI≈ÅY RYNKOWE
    print("\n4Ô∏è‚É£ SI≈ÅY RYNKOWE:")
    avg_attraction = df['attraction_strength'].mean()
    avg_repulsion = df['repulsion_strength'].mean()
    avg_efficiency = df['labor_market_efficiency'].mean()
    
    print(f"   üí™ Si≈Ça przyciƒÖgania: {avg_attraction:.2f}")
    print(f"   üí® Si≈Ça odpychania: {avg_repulsion:.2f}")
    print(f"   ‚öñÔ∏è  Efektywno≈õƒá rynku pracy: {avg_efficiency:.2f}")
    
    # 5. ODPOWIEDZI NA PYTANIA BADAWCZE
    print("\n5Ô∏è‚É£ ODPOWIEDZI NA PYTANIA BADAWCZE:")
    
    # Pytanie 1: Czy regiony z wy≈ºszym bezrobociem majƒÖ ujemne saldo migracji?
    if avg_repulsion < -0.5:
        print("   ‚úÖ TAK: Regiony z wysokim bezrobociem majƒÖ wyra≈∫nie ujemne saldo migracji")
    elif avg_repulsion < 0:
        print("   ‚ö†Ô∏è  CZƒò≈öCIOWO: Regiony z wysokim bezrobociem majƒÖ lekko ujemne saldo migracji")
    else:
        print("   ‚ùå NIE: Regiony z wysokim bezrobociem nie majƒÖ ujemnego salda migracji")
    
    # Pytanie 2: Czy regiony z niskim bezrobociem przyciƒÖgajƒÖ migrant√≥w?
    if avg_attraction > 0.5:
        print("   ‚úÖ TAK: Regiony z niskim bezrobociem wyra≈∫nie przyciƒÖgajƒÖ migrant√≥w")
    elif avg_attraction > 0:
        print("   ‚ö†Ô∏è  CZƒò≈öCIOWO: Regiony z niskim bezrobociem s≈Çabo przyciƒÖgajƒÖ migrant√≥w")
    else:
        print("   ‚ùå NIE: Regiony z niskim bezrobociem nie przyciƒÖgajƒÖ migrant√≥w")
    
    # Pytanie 3: Czy efektywno≈õƒá rynku pracy wp≈Çywa na migracjƒô?
    if avg_efficiency > 1:
        print("   ‚úÖ TAK: Rynek pracy jest efektywny - ludzie migrujƒÖ do region√≥w z niskim bezrobociem")
    elif avg_efficiency > 0:
        print("   ‚ö†Ô∏è  CZƒò≈öCIOWO: Rynek pracy jest s≈Çabo efektywny")
    else:
        print("   ‚ùå NIE: Rynek pracy jest nieefektywny - migracja nie nastƒôpuje zgodnie z bezrobociem")
    
    # 6. TRENDY CZASOWE
    print("\n6Ô∏è‚É£ TRENDY CZASOWE:")
    
    # Sprawd≈∫ trendy dla ka≈ºdego typu migracji
    for migr_type in df['migration_type'].unique():
        type_data = df[df['migration_type'] == migr_type].sort_values('year')
        if len(type_data) >= 3:
            correlations = type_data['correlation'].values
            years = type_data['year'].values
            
            if len(correlations) > 1:
                trend = np.polyfit(years, correlations, 1)[0]
                print(f"   üìä {migr_type.title()}: trend {trend:+.4f}/rok")
    
    # 7. REKOMENDACJE
    print("\n7Ô∏è‚É£ REKOMENDACJE POLITYCZNE:")
    
    if avg_repulsion < -0.5 and avg_attraction > 0.5:
        print("   üéØ REKOMENDACJA 1: Polityka zatrudnienia powinna skupiƒá siƒô na regionach")
        print("      o wysokim bezrobociu, aby zmniejszyƒá odp≈Çyw ludno≈õci")
        print("   üéØ REKOMENDACJA 2: Wspieranie region√≥w atrakcyjnych mo≈ºe zwiƒôkszyƒá")
        print("      ich potencja≈Ç przyciƒÖgania migrant√≥w")
    
    if df['paradoxical_regions_pct'].mean() > 15:
        print("   üéØ REKOMENDACJA 3: Zbadaƒá inne czynniki wp≈ÇywajƒÖce na migracjƒô")
        print("      w regionach paradoksalnych (infrastruktura, edukacja, kultura)")
    
    if avg_efficiency < 0:
        print("   üéØ REKOMENDACJA 4: Poprawa przep≈Çywu informacji o rynku pracy")
        print("      miƒôdzy regionami mo≈ºe zwiƒôkszyƒá efektywno≈õƒá migracji")
    
    # 8. STW√ìRZ WYKRES PODSUMOWUJƒÑCY
    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(16, 12))
    fig.suptitle('Raport ko≈Ñcowy - Analiza przyczynowo-skutkowa', fontsize=16, fontweight='bold')
    
    # Wykres 1: Korelacje wed≈Çug typu migracji
    migration_types = df['migration_type'].unique()
    correlations_by_type = [df[df['migration_type'] == mt]['correlation'].mean() for mt in migration_types]
    
    bars1 = ax1.bar(migration_types, correlations_by_type, 
                   color=['red' if c < 0 else 'green' for c in correlations_by_type])
    ax1.set_ylabel('≈örednia korelacja')
    ax1.set_title('Korelacja wed≈Çug typu migracji')
    ax1.axhline(y=0, color='black', linestyle='--', alpha=0.5)
    ax1.grid(True, alpha=0.3, axis='y')
    
    # Dodaj warto≈õci na s≈Çupkach
    for bar, value in zip(bars1, correlations_by_type):
        height = bar.get_height()
        ax1.text(bar.get_x() + bar.get_width()/2., height + 0.01 if height >= 0 else height - 0.01,
                f'{value:.3f}', ha='center', va='bottom' if height >= 0 else 'top', fontweight='bold')
    
    # Wykres 2: Si≈Çy rynkowe
    forces = ['PrzyciƒÖganie', 'Odpychanie', 'Efektywno≈õƒá']
    force_values = [avg_attraction, avg_repulsion, avg_efficiency]
    colors = ['green', 'red', 'blue']
    
    bars2 = ax2.bar(forces, force_values, color=colors, alpha=0.7)
    ax2.set_ylabel('Si≈Ça')
    ax2.set_title('Si≈Çy rynkowe')
    ax2.axhline(y=0, color='black', linestyle='--', alpha=0.5)
    ax2.grid(True, alpha=0.3, axis='y')
    
    # Dodaj warto≈õci na s≈Çupkach
    for bar, value in zip(bars2, force_values):
        height = bar.get_height()
        ax2.text(bar.get_x() + bar.get_width()/2., height + 0.05 if height >= 0 else height - 0.05,
                f'{value:.2f}', ha='center', va='bottom' if height >= 0 else 'top', fontweight='bold')
    
    # Wykres 3: Klasyfikacja region√≥w
    region_types = ['Atrakcyjne', 'OdpychajƒÖce', 'Paradoksalne', 'Stagnacyjne']
    region_percentages = [
        df['attractive_regions_pct'].mean(),
        df['repulsive_regions_pct'].mean(),
        df['paradoxical_regions_pct'].mean(),
        df['stagnant_regions_pct'].mean()
    ]
    colors3 = ['green', 'red', 'orange', 'gray']
    
    bars3 = ax3.bar(region_types, region_percentages, color=colors3, alpha=0.7)
    ax3.set_ylabel('Procent region√≥w')
    ax3.set_title('Klasyfikacja region√≥w')
    ax3.grid(True, alpha=0.3, axis='y')
    
    # Dodaj warto≈õci na s≈Çupkach
    for bar, value in zip(bars3, region_percentages):
        height = bar.get_height()
        ax3.text(bar.get_x() + bar.get_width()/2., height + 0.5,
                f'{value:.1f}%', ha='center', va='bottom', fontweight='bold')
    
    # Wykres 4: Korelacja w czasie
    yearly_correlation = df.groupby('year')['correlation'].mean()
    ax4.plot(yearly_correlation.index, yearly_correlation.values, 
            marker='o', color='blue', linewidth=3, markersize=8)
    ax4.set_xlabel('Rok')
    ax4.set_ylabel('≈örednia korelacja')
    ax4.set_title('Korelacja w czasie')
    ax4.grid(True, alpha=0.3)
    ax4.axhline(y=0, color='black', linestyle='--', alpha=0.5)
    
    # Zaznacz okresy kryzysowe
    ax4.axvspan(2008, 2010, alpha=0.2, color='red', label='Kryzys finansowy')
    ax4.axvspan(2020, 2021, alpha=0.2, color='orange', label='COVID-19')
    ax4.legend()
    
    plt.tight_layout()
    plt.savefig('raport_koncowy_analiza_przyczynowa.png', dpi=150, bbox_inches='tight')
    plt.close()
    print("\nüìä Zapisano raport ko≈Ñcowy: raport_koncowy_analiza_przyczynowa.png")
    
    print("\n" + "="*80)
    print("‚úÖ ANALIZA PRZYCZYNOWO-SKUTKOWA ZAKO≈ÉCZONA")
    print("="*80)

if __name__ == "__main__":
    analyze_migration_years()
